# Tacotron2

Tacotron2 сеть используется в качестве основного синтезирующего движка в данном проекте, его [реализацию от NVIDIA](https://github.com/NVIDIA/tacotron2), добавлены различные улучшения, которые могут быть найдены в статьях, и сделали код более удобным для пользователя.

Основные отличия:
1. Добавлен модуль [GST](https://arxiv.org/abs/1803.09017);
2. Добавлен Mutual Information Estimator (на основе [статьи](https://arxiv.org/pdf/1909.01145.pdf) и [репозитория](https://github.com/bfs18/tacotron2));
3. Добавлена возможность включения потерь внимания в процесс обучения (с использованием диагонального или [предварительно выровненного](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8703406) направления);
4. Некоторая работа была проведена для улучшения удобства использования кода;
5. Другие незначительные изменения и дополнения.

# Как обучить новую модель

Прежде всего, вам нужно установить все зависимости (которые можно найти в requirements.txt) и преобразовать набор данных в формат LJ Speech, где каждая строка содержит относительный путь к аудиофайлу и его текст, разделенные знаком "|", например:

> wavs/000000.wav|С трев+ожным ч+увством бер+усь я з+а пер+о.

Затем разделите его на два файла: список обучения (90% данных) и список проверки (10% данных).

После этого настройте файл конфигурации по необходимости ([здесь](https://github.com/sovaai/sova-tts-engine/blob/master/data/README.md) можно найти объяснение основных полей файла конфигурации) или просто используйте значение параметров по умолчанию, заполнив значения параметров `output_dir` (куда сохранять контрольные точки), `training_files` (путь к списку обучения), `validation_files` (путь к списку проверки) и `audios_path` (путь к папке с аудиофайлами, так что вместе с относительным путем к аудиофайлу получается полный путь).

Когда все готово, запустите процесс обучения:
* если вы изменили hparams.yaml внутри папки 'data': `python train.py`
* если у вас есть какой-то другой файл конфигурации: `python train.py -p path/to/hparams.yaml`
