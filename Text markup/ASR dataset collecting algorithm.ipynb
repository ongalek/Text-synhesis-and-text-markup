{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основная функция ASR #\n",
    "\n",
    "- Импортируются необходимые библиотеки: speech_recognition, os, pydub, silence из pydub и glob.\n",
    "- Создается объект распознавания речи.\n",
    "- Создается функция get_large_audio_transcription, которая разбивает аудиофайл на куски и применяет к каждому куску распознавание речи.\n",
    "- Аудиофайл открывается с помощью pydub, затем разбивается на куски в местах, где длина тишины равна или больше 200 миллисекунд, и полученные куски сохраняются в переменной chunks.\n",
    "- Создается объект silence с длиной тишины 1500 миллисекунд.\n",
    "- Создается папка \"audio-chunks\" для сохранения полученных кусков.\n",
    "- Куски, длина которых меньше 3 секунд, объединяются в один кусок.\n",
    "- К каждому куску добавляется тишина длиной 1500 миллисекунд.\n",
    "- Каждый кусок экспортируется в формате WAV и сохраняется в папку \"audio-chunks\".\n",
    "- Каждый экспортированный кусок аудио распознается с помощью объекта Recognizer и сохраняется в переменной text.\n",
    "- Если распознавание не удалось из-за неизвестного значения ошибки, выводится сообщение об ошибке.\n",
    "- Если распознавание удалось, то полученный текст приводится к формату заглавной буквы в начале предложения и сохраняется в переменную whole_text.\n",
    "- Экспортированный кусок аудио сохраняется в папку, заданную в пути os.path.join().\n",
    "- Возвращается список whole_text с распознанным текстом и счетчик cnt, который увеличивается на единицу для каждого сохраненного куска аудио."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import glob\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path,cnt):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_mp3(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,min_silence_len=200, silence_thresh=-40) \n",
    "    silence = AudioSegment.silent(duration=1500)\n",
    "    folder_name = \"audio-chunks\"\n",
    "    target_length = 3*1000\n",
    "    output_chunks = [chunks[0]]\n",
    "    for chunk in chunks[1:]:\n",
    "        if len(output_chunks[-1]) < target_length:\n",
    "            output_chunks[-1] += chunk \n",
    "        else:\n",
    "            output_chunks.append(chunk)\n",
    "    for i in range(len(output_chunks)):\n",
    "        output_chunks[i] = output_chunks[i] + silence\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    else: \n",
    "        files = glob.glob(folder_name + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    whole_text = []\n",
    "    \n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(output_chunks):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened,language=\"ru-RU\")\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text.append(text)\n",
    "                audio_chunk.export(os.path.join(r'C:\\Users\\wwwjo\\Desktop\\SII\\DIP_lom\\data', f\"chunk{cnt}.wav\"), format=\"wav\")\n",
    "                cnt += 1\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text, cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск мультифайлового распознавания речи #\n",
    "- Объявляется переменная cnt со значением 0, которая будет использоваться для создания уникальных имен файлов.\n",
    "- С помощью функции glob.glob() выбираются все файлы в указанной папке r'C:\\Users\\wwwjo\\Desktop\\SII\\DIP_lom\\input_data\\opergamer\\'.\n",
    "- Создаются переменные epoch и transcriptions. Переменная epoch не используется в данном коде. Переменная transcriptions будет использоваться для хранения всех полученных транскрипций.\n",
    "- Начинается цикл for, который проходится по всем файлам, выбранным в шаге 2.\n",
    "- Вызывается функция get_large_audio_transcription(), которая принимает путь к аудио файлу и текущее значение cnt. Функция разбивает аудио файл на чанки и применяет к каждому чанку распознавание речи с помощью Google Speech API. Также сохраняются полученные транскрипции в переменной whole_text.\n",
    "- После выполнения функции get_large_audio_transcription(), все полученные транскрипции добавляются в список transcriptions.\n",
    "- Печатается текущее значение cnt, чтобы отслеживать количество созданных файлов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "files = glob.glob(r'C:\\Users\\wwwjo\\Desktop\\SII\\DIP_lom\\input_data\\opergamer\\*') # выбор необходимой папки с файлами для создания\n",
    "epoch = 0\n",
    "transcriptions = []\n",
    "for f in files:\n",
    "    # epoch +=1\n",
    "    # print(f)\n",
    "    # if epoch >2: \n",
    "    #     break\n",
    "    trans, cnt = get_large_audio_transcription(f,cnt)\n",
    "    for i in trans:\n",
    "        transcriptions.append(i)\n",
    "    print(cnt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание датасета на основе аудиосегментов с транскрипцией #\n",
    "- Импортируется библиотека Pandas для работы с таблицами данных.\n",
    "- Создается пустой объект DataFrame с двумя столбцами 'Name' и 'Transcript'.\n",
    "- В цикле проходятся все полученные транскрипты, и для каждого транскрипта создается новая строка в объекте DataFrame, где в столбец 'Name' записывается имя файла в формате \"data{i}\", а в столбец 'Transcript' записывается соответствующий транскрипт.\n",
    "- Полученный DataFrame экспортируется в Excel-файл с помощью метода to_excel(), указывая путь к файлу, отключение индекса и наличие заголовка только на первой строке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Name', 'Transcript'])\n",
    "for i in range(len(transcriptions)):\n",
    "    df = df.append({\"Name\": 'data{0}'.format(i),'Transcript': transcriptions[i]},ignore_index=True)\n",
    "df.to_excel(r'C:\\Users\\wwwjo\\Desktop\\SII\\DIP_lom\\DATASET.xlsx', index=False, header=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация транскрипций #\n",
    "- Импортируется библиотека transliterate, которая используется для транслитерации кириллических символов на латинские.\n",
    "- В цикле проходится по каждой строке датафрейма и производится транслитерация русских слов на латиницу с помощью функции translit из библиотеки transliterate.\n",
    "- Заменяются некоторые латинские символы на русские эквиваленты с помощью метода replace.\n",
    "- Измененный датафрейм сохраняется в том же Excel-файле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transliterate\n",
    "from transliterate import translit\n",
    "for i in range(len(df)):\n",
    "    text = df['Transcript'][i]\n",
    "    text = translit(df['Transcript'][i], 'ru')\n",
    "    text = text.replace('w','в')\n",
    "    text = text.replace('W','В')\n",
    "    text = text.replace('q','ку')\n",
    "    text = text.replace('Q','Ку')\n",
    "    df['Transcript'][i] = text\n",
    "df.to_excel(r'C:\\Users\\wwwjo\\Desktop\\SII\\DIP_lom\\DATASET.xlsx', index=False, header=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4eee2d32bef15c2710912eebfae02ee091672c255d5e79a4cfe4aa76c74a1146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
